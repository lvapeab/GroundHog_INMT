{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 1080 (CNMeM is disabled, cuDNN 5005)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ONLINE ALGORITHMS\n",
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "import theano.tensor as TT\n",
    "import numpy\n",
    "import argparse\n",
    "import cPickle\n",
    "import traceback\n",
    "import logging\n",
    "import copy\n",
    "import time\n",
    "import sys\n",
    "from collections import OrderedDict\n",
    "from experiments.nmt import \\\n",
    "    RNNEncoderDecoder, \\\n",
    "    prototype_phrase_state, \\\n",
    "    parse_input\n",
    "from experiments.nmt.numpy_compat import argpartition\n",
    "from isles_utils import compute_mouse_movements, find_isles, is_sublist, subfinder\n",
    "from experiments.nmt.online.online_utils import create_batch_from_seqs, loadSourceLanguageFromState, \\\n",
    "    loadTargetLanguageFromState\n",
    "from groundhog.datasets.UnbufferedDataIterator import UnbufferedDataIterator\n",
    "from groundhog.trainer.SGD_online import SGD\n",
    "from groundhog.trainer.SGD_adadelta_online import SGD as Adadelta\n",
    "from groundhog.utils import print_time\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "state = prototype_phrase_state()\n",
    "statepkl = '/media/HDD_2TB/MODELS/xerox/esen/models/xerox_289_354_state.pkl'\n",
    "with open(statepkl) as src:\n",
    "    state.update(cPickle.load(src))\n",
    "sourceLanguage = loadSourceLanguageFromState(state)\n",
    "targetLanguage = loadTargetLanguageFromState(state)\n",
    "i=0\n",
    "rng = numpy.random.RandomState(state['seed'])\n",
    "enc_decs = []\n",
    "enc_decs.append(RNNEncoderDecoder(state, rng, skip_init=True, compute_alignment=1))\n",
    "enc_decs[i].build()\n",
    "lm_models=[]\n",
    "lm_models.append(enc_decs[i].create_lm_model())\n",
    "models =['/media/HDD_2TB/MODELS/xerox/esen/models/xerox_289_354_model_bleu50.npz']\n",
    "source = '/media/HDD_2TB/DATASETS/xerox/DATA/test.es'\n",
    "trans = '/media/HDD_2TB/DATASETS/xerox/DATA/test.en'\n",
    "num_sentences = 1\n",
    "batch_iters=[]\n",
    "batch_iters.append(UnbufferedDataIterator(source, trans, state,\n",
    "                                          sourceLanguage.word_indx,\n",
    "                                          targetLanguage.word_indx, \n",
    "                                          sourceLanguage.indx_word,\n",
    "                                          targetLanguage.indx_word,\n",
    "                                          num_sentences, state['seqlen'], None))\n",
    "print \"Model loaded\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class AdaGrad(object):\n",
    "    \"\"\"\n",
    "    Adagrad [1] is an algorithm for gradient-based optimization \n",
    "    that adapts the learning rate to the parameters, performing\n",
    "    larger updates for infrequent and smaller updates for frequent parameters.\n",
    "    \n",
    "    We set g_{t,i} to be the gradient of the objective function w.r.t. to the parameter θi at time step t\n",
    "    gt,i=∇θJ(θi)\n",
    "    Adagrad modifies the general learning rate η at each time step t for every parameter θi based\n",
    "    on the past gradients that have been computed for θi:\n",
    "    θ{t+1,i}=θ{t,i}−\\div{η}{\\sqrt{G_{t,ii}+ϵ}}*g_{t,i}\n",
    "\n",
    "    Gt∈ℝ^{d×d}: Diagonal matrix where each diagonal element i,i is the sum of the squares of the gradients w.r.t. θi up to time step t\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 model,\n",
    "                 state,\n",
    "                 data):\n",
    "\n",
    "        #####################################\n",
    "        # Step 0. Constructs shared variables\n",
    "        #####################################\n",
    "\n",
    "        bs = state['bs']\n",
    "        self.model = model\n",
    "        self.rng = numpy.random.RandomState(state['seed'])\n",
    "\n",
    "        self.add_noise = state['weight_noise']\n",
    "        self.step = 0\n",
    "        self.bs = bs\n",
    "        self.state = state\n",
    "        self.data = data\n",
    "        self.step_timer = time.time()\n",
    "        self.gdata = [theano.shared(numpy.zeros( (2,)*x.ndim,\n",
    "                                                dtype=x.dtype),\n",
    "                                    name=x.name) for x in model.inputs]\n",
    "        self.gs = [theano.shared(numpy.zeros(p.get_value(borrow=True).shape,\n",
    "                                             dtype=theano.config.floatX),\n",
    "                                name=p.name)\n",
    "                   for p in model.params]\n",
    "\n",
    "        self.eps = 1e-4\n",
    "        if 'profile' not in self.state:\n",
    "            self.state['profile'] = 0\n",
    "\n",
    "        ###################################\n",
    "        # Step 1. Compile training function\n",
    "        ###################################\n",
    "        print 'Constructing grad function'\n",
    "        loc_data = self.gdata\n",
    "        lr = TT.scalar('lr')\n",
    "        self.prop_names = [x[0] for x in model.properties]\n",
    "        self.prop_exprs = [x[1] for x in model.properties]\n",
    "        self.update_rules = [x[1] for x in model.updates]\n",
    "        inputs_replacement_list = zip(model.inputs, loc_data)\n",
    "\n",
    "\n",
    "        accumulated_squared_gradients = [theano.shared(numpy.zeros(param.shape.eval(),\n",
    "                                                                   dtype=param.dtype),\n",
    "                                                       name = param.name + '_acc_grad')\n",
    "                                         for param in model.params]\n",
    "\n",
    "        output_values = []\n",
    "        st = time.time()\n",
    "\n",
    "        def shift_zeroes(x):\n",
    "            # The formula would create NaN upon the presence of zeroes\n",
    "            return x + (abs(x) < 1e-8) * 1e-8\n",
    "\n",
    "\n",
    "        def nan_and_inf_to_zero(x):\n",
    "            x = TT.switch(TT.isnan(x), 0.0, x)\n",
    "            return TT.switch(TT.isinf(x), 1e8, x)\n",
    "\n",
    "\n",
    "        no_nan_or_inf_gradients = [nan_and_inf_to_zero(gradient) for gradient in self.gs]\n",
    "\n",
    "        # Compute G_{i,i}\n",
    "        accumulated_squared_gradients_update_list = [(acc_gradient, acc_gradient + gradient**2)\n",
    "                                        for acc_gradient, gradient in\n",
    "                                        zip(accumulated_squared_gradients, no_nan_or_inf_gradients)]\n",
    "\n",
    "        # θ{t+1,i}=θ{t,i}−\\div{η}{\\sqrt{G_{t,ii}+ϵ}}*g_{t,i}\n",
    "        weight_update_list = [(weight, weight - lr / TT.sqrt(TT.inc_subtensor(G_t[1][:],  1e-8)+TT.pow(gradient, 2))\n",
    "                               * gradient) for weight, gradient, G_t\n",
    "                              in zip(model.params, no_nan_or_inf_gradients, accumulated_squared_gradients_update_list)]\n",
    "\n",
    "        updates = weight_update_list + accumulated_squared_gradients_update_list\n",
    "        print 'Compiling update function'\n",
    "        self.lr = numpy.float32(state['lr'])\n",
    "        print '\\t > Using a learning rate of', self.lr\n",
    "        self.update_fn = theano.function(\n",
    "            [lr], output_values, name='update_function',\n",
    "            allow_input_downcast=True,updates = updates,\n",
    "            profile=self.state['profile'],\n",
    "            )\n",
    "\n",
    "        print 'took', time.time() - st\n",
    "\n",
    "        self.old_cost = 1e20\n",
    "        self.schedules = model.get_schedules()\n",
    "        self.return_names = self.prop_names + \\\n",
    "                ['cost',\n",
    "                 'time_step',\n",
    "                 'whole_time']\n",
    "\n",
    "\n",
    "    def __call__(self, _):\n",
    "        \"\"\"\n",
    "        Ignored parameter: hypothesis.\n",
    "        \"\"\"\n",
    "        batch = self.data.next()\n",
    "\n",
    "        \"\"\"\n",
    "        # Perturb the data (! and the model)\n",
    "        if self.add_noise:\n",
    "            if isinstance(batch, dict):\n",
    "                batch = self.model.perturb(**batch)\n",
    "            else:\n",
    "                batch = self.model.perturb(*batch)\n",
    "        \"\"\"\n",
    "        # Load the dataset into GPU\n",
    "        # Note: not the most efficient approach in general, as it involves\n",
    "        # each batch is copied individually on gpu\n",
    "        if isinstance(batch, dict):\n",
    "            for gdata in self.gdata:\n",
    "                # print batch[gdata.name]\n",
    "                gdata.set_value(batch[gdata.name], borrow=True)\n",
    "        else:\n",
    "            for gdata, data in zip(self.gdata, batch):\n",
    "                gdata.set_value(data, borrow=True)\n",
    "\n",
    "\n",
    "        g_st = time.time()\n",
    "        rvals = self.update_fn(self.lr)\n",
    "        g_ed = time.time()\n",
    "        whole_time = time.time() - self.step_timer\n",
    "        if self.step % self.state['trainFreq'] == 0:\n",
    "            msg = '.. iter %s'\n",
    "            vals = [self.step]\n",
    "            for dx, prop in enumerate(self.prop_names):\n",
    "                msg += ' '+prop+' %.2e'\n",
    "            msg += ' step time %s whole time %s lr %.2e'\n",
    "            vals += [print_time(g_ed - g_st),\n",
    "                     print_time(time.time() - self.step_timer),\n",
    "                     float(self.lr)]\n",
    "            print msg % tuple(vals)\n",
    "        self.step += 1\n",
    "        ret = dict([('lr', float(self.lr)),\n",
    "                       ('time_step', float(g_ed - g_st)),\n",
    "                       ('whole_time', float(whole_time))]+zip(self.prop_names, rvals))\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing grad function\n",
      "Compiling update function\n",
      "\t > Using a learning rate of 1.0\n",
      "took 4.99089097977\n"
     ]
    }
   ],
   "source": [
    "#from groundhog.trainer.SGD_adagrad import AdaGrad\n",
    "algos = []\n",
    "algos.append(eval('AdaGrad')(lm_models[i], state, batch_iters[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lm_models[i].param_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "src_seq = [1,2,34,5,6,7,8]\n",
    "hypothesis = [3,54,6,7,8,2,1]\n",
    "\n",
    "hypothesis_batch = create_batch_from_seqs(src_seq, hypothesis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float argument required, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-5330fbcf2efa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0malgos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhypothesis_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-18-8136d6f9427c>\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, _)\u001b[0m\n\u001b[0;32m    147\u001b[0m                      \u001b[0mprint_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_timer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m                      float(self.lr)]\n\u001b[1;32m--> 149\u001b[1;33m             \u001b[1;32mprint\u001b[0m \u001b[0mmsg\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m         ret = dict([('lr', float(self.lr)),\n",
      "\u001b[1;31mTypeError\u001b[0m: float argument required, not str"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "algos[i](hypothesis_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
