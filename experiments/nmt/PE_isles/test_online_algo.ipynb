{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "import theano.tensor as TT\n",
    "import numpy\n",
    "import argparse\n",
    "import cPickle\n",
    "import traceback\n",
    "import logging\n",
    "import copy\n",
    "import time\n",
    "import sys\n",
    "from collections import OrderedDict\n",
    "from experiments.nmt import \\\n",
    "    RNNEncoderDecoder, \\\n",
    "    prototype_phrase_state, \\\n",
    "    parse_input\n",
    "from experiments.nmt.numpy_compat import argpartition\n",
    "from isles_utils import compute_mouse_movements, find_isles, is_sublist, subfinder\n",
    "from experiments.nmt.online.online_utils import create_batch_from_seqs, loadSourceLanguageFromState, \\\n",
    "    loadTargetLanguageFromState\n",
    "from groundhog.datasets.UnbufferedDataIterator import UnbufferedDataIterator\n",
    "from groundhog.trainer.SGD_online import SGD\n",
    "from groundhog.trainer.SGD_adadelta_online import SGD as Adadelta\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "state = prototype_phrase_state()\n",
    "statepkl = '/media/HDD_2TB/MODELS/xerox/esen/models/xerox_289_354_state.pkl'\n",
    "with open(statepkl) as src:\n",
    "    state.update(cPickle.load(src))\n",
    "sourceLanguage = loadSourceLanguageFromState(state)\n",
    "targetLanguage = loadTargetLanguageFromState(state)\n",
    "i=0\n",
    "rng = numpy.random.RandomState(state['seed'])\n",
    "enc_decs = []\n",
    "enc_decs.append(RNNEncoderDecoder(state, rng, skip_init=True, compute_alignment=1))\n",
    "enc_decs[i].build()\n",
    "lm_models=[]\n",
    "lm_models.append(enc_decs[i].create_lm_model())\n",
    "models =['/media/HDD_2TB/MODELS/xerox/esen/models/xerox_289_354_model_bleu50.npz']\n",
    "source = '/media/HDD_2TB/DATASETS/xerox/DATA/test.es'\n",
    "trans = '/media/HDD_2TB/DATASETS/xerox/DATA/test.en'\n",
    "num_sentences = 1\n",
    "batch_iters=[]\n",
    "batch_iters.append(UnbufferedDataIterator(source, trans, state,\n",
    "                                          sourceLanguage.word_indx,\n",
    "                                          targetLanguage.word_indx, \n",
    "                                          sourceLanguage.indx_word,\n",
    "                                          targetLanguage.indx_word,\n",
    "                                          num_sentences, state['seqlen'], None))\n",
    "print \"Model loaded\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class AdaGrad(object):\n",
    "    \"\"\"\n",
    "    Adagrad [1] is an algorithm for gradient-based optimization \n",
    "    that adapts the learning rate to the parameters, performing\n",
    "    larger updates for infrequent and smaller updates for frequent parameters.\n",
    "    \n",
    "    We set g_{t,i} to be the gradient of the objective function w.r.t. to the parameter θi at time step t\n",
    "    gt,i=∇θJ(θi)\n",
    "    Adagrad modifies the general learning rate η at each time step t for every parameter θi based\n",
    "    on the past gradients that have been computed for θi:\n",
    "    θ{t+1,i}=θ{t,i}−\\div{η}{\\sqrt{G_{t,ii}+ϵ}}*g_{t,i}\n",
    "\n",
    "    Gt∈ℝ^{d×d}: Diagonal matrix where each diagonal element i,i is the sum of the squares of the gradients w.r.t. θi up to time step t\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 model,\n",
    "                 state,\n",
    "                 data):\n",
    "\n",
    "        #####################################\n",
    "        # Step 0. Constructs shared variables\n",
    "        #####################################\n",
    "\n",
    "        bs = state['bs']\n",
    "        self.model = model\n",
    "        self.rng = numpy.random.RandomState(state['seed'])\n",
    "\n",
    "        self.add_noise = state['weight_noise']\n",
    "        self.step = 0\n",
    "        self.bs = bs\n",
    "        self.state = state\n",
    "        self.data = data\n",
    "        self.step_timer = time.time()\n",
    "        self.gdata = [theano.shared(numpy.zeros( (2,)*x.ndim,\n",
    "                                                dtype=x.dtype),\n",
    "                                    name=x.name) for x in model.inputs]\n",
    "        self.gs = [theano.shared(numpy.zeros(p.get_value(borrow=True).shape,\n",
    "                                             dtype=theano.config.floatX),\n",
    "                                name=p.name)\n",
    "                   for p in model.params]\n",
    "        \n",
    "        self.eps = 1e-4\n",
    "        if 'profile' not in self.state:\n",
    "            self.state['profile'] = 0\n",
    "\n",
    "        ###################################\n",
    "        # Step 1. Compile training function\n",
    "        ###################################\n",
    "        print 'Constructing grad function'\n",
    "        loc_data = self.gdata\n",
    "        lr = TT.scalar('lr')\n",
    "        self.prop_names = [x[0] for x in model.properties]\n",
    "        self.prop_exprs = [x[1] for x in model.properties]\n",
    "        self.update_rules = [x[1] for x in model.updates]\n",
    "        inputs_replacement_list = zip(model.inputs, loc_data)\n",
    "\n",
    "        parameter_gradients = theano.clone(model.param_grads, replace = inputs_replacement_list)\n",
    "\n",
    "            \n",
    "        accumulated_squared_gradients = [theano.shared(numpy.zeros(param.shape.eval(),\n",
    "                                                                   dtype=param.dtype),\n",
    "                                                       name = param.name + '_acc_grad')\n",
    "                                         for param in model.params]\n",
    "\n",
    "        output_values = []\n",
    "        st = time.time()\n",
    "        \n",
    "        def shift_zeroes(x):\n",
    "            # The formula would create NaN upon the presence of zeroes\n",
    "            return x + (abs(x) < 1e-8) * 1e-8\n",
    "        \n",
    "        \n",
    "        def nan_and_inf_to_zero(x):\n",
    "            x = TT.switch(TT.isnan(x), 0.0, x)\n",
    "            return TT.switch(TT.isinf(x), 1e8, x)\n",
    "        \n",
    "\n",
    "        no_nan_or_inf_gradients = [nan_and_inf_to_zero(gradient) for gradient in parameter_gradients]\n",
    "        accumulated_squared_gradients_update = [(acc_gradient, acc_gradient + gradient**2)\n",
    "                                        for acc_gradient, gradient in\n",
    "                                        zip(accumulated_squared_gradients, no_nan_or_inf_gradients)]\n",
    "        \n",
    "        \n",
    "        weight_update_list = [(weight, weight - lr / TT.sqrt(TT.inc_subtensor(G_t[1][:],  1e-8)+TT.pow(gradient, 2))\n",
    "                               * gradient) for weight, gradient, G_t \n",
    "                              in zip(model.params, no_nan_or_inf_gradients, accumulated_squared_gradients_update)]\n",
    "        \n",
    "        \n",
    "        updates = weight_update_list + accumulated_squared_gradients_update\n",
    "        print 'Compiling update function'\n",
    "        self.lr = numpy.float32(state['lr'])\n",
    "        print '\\t > Using a learning rate of', self.lr\n",
    "        self.update_fn = theano.function(\n",
    "            [lr], output_values, name='update_function',\n",
    "            allow_input_downcast=True,updates = updates,\n",
    "            profile=self.state['profile'],\n",
    "            )\n",
    "\n",
    "        print 'took', time.time() - st\n",
    "\n",
    "        self.old_cost = 1e20\n",
    "        self.schedules = model.get_schedules()\n",
    "        self.return_names = self.prop_names + \\\n",
    "                ['cost',\n",
    "                 'time_step',\n",
    "                 'whole_time']\n",
    "\n",
    "    def __call__(self, _):\n",
    "        \"\"\"\n",
    "        Ignored parameter: hypothesis.\n",
    "        \"\"\"\n",
    "        batch = self.data.next()\n",
    "\n",
    "        \"\"\"\n",
    "        # Perturb the data (! and the model)\n",
    "        if self.add_noise:\n",
    "            if isinstance(batch, dict):\n",
    "                batch = self.model.perturb(**batch)\n",
    "            else:\n",
    "                batch = self.model.perturb(*batch)\n",
    "        \"\"\"\n",
    "        # Load the dataset into GPU\n",
    "        # Note: not the most efficient approach in general, as it involves\n",
    "        # each batch is copied individually on gpu\n",
    "        if isinstance(batch, dict):\n",
    "            for gdata in self.gdata:\n",
    "                # print batch[gdata.name]\n",
    "                gdata.set_value(batch[gdata.name], borrow=True)\n",
    "        else:\n",
    "            for gdata, data in zip(self.gdata, batch):\n",
    "                gdata.set_value(data, borrow=True)\n",
    "\n",
    "        rvals = self.update_fn()\n",
    "        if len(rvals) > 0:\n",
    "            print rvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing grad function\n",
      "Compiling update function\n",
      "\t > Using a learning rate of 1.0\n"
     ]
    },
    {
     "ename": "MissingInputError",
     "evalue": "An input of the graph, used to compute Subtensor{::int64}(x, Constant{-1}), was not provided and not given a value.Use the Theano flag exception_verbosity='high',for more information on this error.\n\nBacktrace when the variable is created:\n  File \"/home/lvapeab/software/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/lvapeab/software/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 391, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/lvapeab/software/anaconda/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 199, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/lvapeab/software/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2723, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/lvapeab/software/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2825, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/lvapeab/software/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2885, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-60-9825e4d9ccaa>\", line 31, in <module>\n    enc_decs[i].build()\n  File \"build/bdist.linux-x86_64/egg/experiments/nmt/encdec.py\", line 1325, in build\n    self.x = TT.lmatrix('x')\n",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMissingInputError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-147-539ea16a1bc4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#from groundhog.trainer.SGD_adagrad import AdaGrad\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0malgos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0malgos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'AdaGrad'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlm_models\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_iters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-146-74e0ced7c736>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, model, state, data)\u001b[0m\n\u001b[0;32m     96\u001b[0m             \u001b[1;33m[\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'update_function'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m             \u001b[0mallow_input_downcast\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mupdates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdates\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m             \u001b[0mprofile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'profile'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m             )\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/lvapeab/software/anaconda/lib/python2.7/site-packages/theano/compile/function.pyc\u001b[0m in \u001b[0;36mfunction\u001b[1;34m(inputs, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input)\u001b[0m\n\u001b[0;32m    320\u001b[0m                    \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m                    \u001b[0mprofile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m                    output_keys=output_keys)\n\u001b[0m\u001b[0;32m    323\u001b[0m     \u001b[1;31m# We need to add the flag check_aliased inputs if we have any mutable or\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m     \u001b[1;31m# borrowed used defined inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/lvapeab/software/anaconda/lib/python2.7/site-packages/theano/compile/pfunc.pyc\u001b[0m in \u001b[0;36mpfunc\u001b[1;34m(params, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input, output_keys)\u001b[0m\n\u001b[0;32m    478\u001b[0m                          \u001b[0maccept_inplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_inplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m                          \u001b[0mprofile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 480\u001b[1;33m                          output_keys=output_keys)\n\u001b[0m\u001b[0;32m    481\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/lvapeab/software/anaconda/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36morig_function\u001b[1;34m(inputs, outputs, mode, accept_inplace, name, profile, on_unused_input, output_keys)\u001b[0m\n\u001b[0;32m   1781\u001b[0m                    \u001b[0mprofile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1782\u001b[0m                    \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1783\u001b[1;33m                    \u001b[0moutput_keys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1784\u001b[0m             defaults)\n\u001b[0;32m   1785\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/lvapeab/software/anaconda/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, inputs, outputs, mode, accept_inplace, function_builder, profile, on_unused_input, fgraph, output_keys)\u001b[0m\n\u001b[0;32m   1433\u001b[0m             \u001b[1;31m# OUTPUT VARIABLES)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1434\u001b[0m             fgraph, additional_outputs = std_fgraph(inputs, outputs,\n\u001b[1;32m-> 1435\u001b[1;33m                                                     accept_inplace)\n\u001b[0m\u001b[0;32m   1436\u001b[0m             \u001b[0mfgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprofile\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1437\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/lvapeab/software/anaconda/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36mstd_fgraph\u001b[1;34m(input_specs, output_specs, accept_inplace)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m     fgraph = gof.fg.FunctionGraph(orig_inputs, orig_outputs,\n\u001b[1;32m--> 176\u001b[1;33m                                   update_mapping=update_mapping)\n\u001b[0m\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_nodes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/lvapeab/software/anaconda/lib/python2.7/site-packages/theano/gof/fg.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, inputs, outputs, features, clone, update_mapping)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__import_r__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"init\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m             \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclients\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'output'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/lvapeab/software/anaconda/lib/python2.7/site-packages/theano/gof/fg.pyc\u001b[0m in \u001b[0;36m__import_r__\u001b[1;34m(self, variable, reason)\u001b[0m\n\u001b[0;32m    374\u001b[0m         \u001b[1;31m# Imports the owners of the variables\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvariable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mowner\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mvariable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mowner\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_nodes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 376\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__import__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mowner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreason\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    377\u001b[0m         if (variable.owner is None and\n\u001b[0;32m    378\u001b[0m                 \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConstant\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/lvapeab/software/anaconda/lib/python2.7/site-packages/theano/gof/fg.pyc\u001b[0m in \u001b[0;36m__import__\u001b[1;34m(self, apply_node, check, reason)\u001b[0m\n\u001b[0;32m    416\u001b[0m                             \u001b[1;34m\"for more information on this error.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m                             % str(node)),\n\u001b[1;32m--> 418\u001b[1;33m                             variable=r)\n\u001b[0m\u001b[0;32m    419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnew_nodes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMissingInputError\u001b[0m: An input of the graph, used to compute Subtensor{::int64}(x, Constant{-1}), was not provided and not given a value.Use the Theano flag exception_verbosity='high',for more information on this error.\n\nBacktrace when the variable is created:\n  File \"/home/lvapeab/software/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/lvapeab/software/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 391, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/lvapeab/software/anaconda/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 199, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/lvapeab/software/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2723, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/lvapeab/software/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2825, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/lvapeab/software/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2885, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-60-9825e4d9ccaa>\", line 31, in <module>\n    enc_decs[i].build()\n  File \"build/bdist.linux-x86_64/egg/experiments/nmt/encdec.py\", line 1325, in build\n    self.x = TT.lmatrix('x')\n"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "#from groundhog.trainer.SGD_adagrad import AdaGrad\n",
    "algos = []\n",
    "algos.append(eval('AdaGrad')(lm_models[i], state, batch_iters[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}